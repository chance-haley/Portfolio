{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "467a46ce-a17f-45c2-8d3b-50ffe1bfd4a2",
   "metadata": {},
   "source": [
    "# Logistic-Regression Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c4d86-4875-4332-8e0c-dafc314f10fe",
   "metadata": {},
   "source": [
    "We will use a version of the famous Titanic data set that requires very little cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750d517f-fe6d-46b6-9809-77a15136c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277147d-7faf-4dd1-990d-64cbbb15de00",
   "metadata": {},
   "source": [
    "Read in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ae51e4-1e56-47e2-b288-fc3f4a6b74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.read_csv('titanic_data.csv', index_col='PassengerId')\n",
    "t_df = t_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea14e68-1180-407c-aac5-59958fce899c",
   "metadata": {},
   "source": [
    "Remove columns that don't make reasonable numeric predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8fed58-d03e-496f-9d7e-7d38fddc23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df.drop(columns=['Name', 'Cabin', 'Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25460f8-9af7-4dd7-b805-baf40bfe8fed",
   "metadata": {},
   "source": [
    "Convert the remaining columns to use numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02720341-835c-4737-b07a-2ab69c86fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df['Sex'].replace(['male', 'female'], [1, 0], inplace=True)\n",
    "t_df['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca55713-f6bb-4414-b058-5f5d1d43cc69",
   "metadata": {},
   "source": [
    "Extract the dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0438fe4c-3909-4947-b45b-186c78078d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t_df.drop(columns=['Survived'])\n",
    "y = t_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eefd827-02ef-4469-9278-6e7d518bb16f",
   "metadata": {},
   "source": [
    "Split training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5422b95-e3ed-4e02-a83c-da21d5b75e9d",
   "metadata": {},
   "source": [
    "Notice that we are  _practicing to learn_, not creating a product, so we have not paid attention to validation vs. test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd15ccd5-9bcc-4c66-a1ef-489c22777346",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426daf8-24c0-455c-8a75-61000d8a29e1",
   "metadata": {},
   "source": [
    "### Run everything up to this point and check the variable explorer for the following.\n",
    "#### Do you have distinct training and test sets for the independent and dependent variables? Put the answer in your Jupyter notebook. Include the sizes of the sets in cardinality and percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b8bd5-2eaf-481b-86c6-fce52890e83f",
   "metadata": {},
   "source": [
    "#### Look at the two training sets and at least one test set to verify they contain what you expect.\n",
    "Are there any issues? Put the answer in your Jupyter notebook. Include an explanation or discussion if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba9932fd-03a9-4f44-b941-948619ae0e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  128\n",
      "Model:                          Logit   Df Residuals:                      120\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 29 Oct 2024   Pseudo R-squ.:                  0.3126\n",
      "Time:                        13:27:59   Log-Likelihood:                -57.049\n",
      "converged:                       True   LL-Null:                       -82.996\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.124e-09\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.2842      1.372      3.124      0.002       1.596       6.972\n",
      "Pclass        -0.3167      0.507     -0.624      0.532      -1.311       0.678\n",
      "Sex           -2.9603      0.602     -4.917      0.000      -4.140      -1.780\n",
      "Age           -0.0381      0.018     -2.137      0.033      -0.073      -0.003\n",
      "SibSp         -0.0249      0.392     -0.064      0.949      -0.792       0.743\n",
      "Parch         -0.5595      0.429     -1.305      0.192      -1.400       0.281\n",
      "Fare           0.0029      0.005      0.625      0.532      -0.006       0.012\n",
      "Embarked       0.4590      0.499      0.920      0.358      -0.519       1.437\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logmodel = sm.Logit(y_train, sm.add_constant(X_train)).fit(disp=False)\n",
    "print(logmodel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce86115-d7d6-4cff-b519-5c6a545f31eb",
   "metadata": {},
   "source": [
    "### Are there any predictors that are not statistically significant in the conventional sense?\n",
    "Put the answer in your Jupyter notebook.<p>\n",
    "A variable is conventionally statistically significant if its _p_ value is less than 0.05. (Do you know why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7f628-320a-4645-910c-ac38384e5c77",
   "metadata": {},
   "source": [
    "### What variable is particularly strong in predicting survival?\n",
    "Put the answer in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fe52b-fca6-4bc8-8df6-3ec3e2e9f07a",
   "metadata": {},
   "source": [
    "### What does a negative coefficient imply and why?\n",
    "Put the answer in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b45e0-2b4b-43bb-82b1-6bb8fb8a5173",
   "metadata": {},
   "source": [
    "### Based on your discussion, first think about what other variable ought to be a decent predictor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd8241-c8a6-44e6-9487-f8d585ea35d9",
   "metadata": {},
   "source": [
    "### Next, check the report output to see if that was the case.\n",
    "Enter what variable you thought might be a good predictor and whether that turned out to be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777744d7-7575-45b0-9481-fb7905c0e0c4",
   "metadata": {},
   "source": [
    "## Next, we wil learn about the quality of our predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4560c-516f-415c-b43f-328aba6c6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Form our predictions, convert continuous [0, 1] predictions to binary\n",
    "predictions = logmodel.predict(sm.add_constant(X_test))\n",
    "bin_predictions = [1 if x >= 0.5 else 0 for x in predictions]\n",
    "\n",
    "# We can now assess the accuracy and print out the confusion matrix\n",
    "print(accuracy_score(y_test, bin_predictions))\n",
    "print(confusion_matrix(y_test, bin_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8df56-0d09-490d-8084-5582dd37c16b",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d3f46b-24ed-4666-a72e-5bf6e975b99e",
   "metadata": {},
   "source": [
    "### There is another way to evaluate our model... for a variety of thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3290d-8a04-42a7-ad90-2da217b1eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC Curve (area = %0.3f)' % roc_auc)\n",
    "plt.title('ROC Curve (area = %0.3f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
